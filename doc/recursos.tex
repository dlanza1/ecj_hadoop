Mencionamos en primer lugar las dos herramientas m\'as importantes del proyecto, las dos que hemos integrado, ECJ y Hadoop.

La herramienta de c\'omputo evolutivo \textbf{ECJ}, ha sido desarrollada por el laboratorio de computaci\'on evolutiva de la universidad George Mason en Georgia, EEUU. Desde su primera implementaci\'on se han ido publicando numerosas versiones, llegando a su versi\'on 22, siendo esta la \'ultima y la utilizada en este proyecto.

La otra herramienta integrada, Hadoop, est\'a siendo incubada por la organizaci\'on de software Apache y posee dos vertientes en su sistema de versionado. La versi\'on primera de esta herramienta, conocida como MapReduce, continua en uso por muchas organizaciones y empresas, a\'un se le da mantenimiento por la comunidad de desarrolladores, aunque cada vez con menos intensidad. Durante el desarrollo de esta primera versi\'on surgió un gran cambio en el dise\~no de la herramienta, este cambio provoc\'o que se comenzara con la segunda versi\'on del proyecto conocida como \textbf{YARN}. Esta segunda versi\'on ha sido la utilizada en este proyecto ya que est\'a adquiriendo cada vez m\'as popularidad por su uso m\'as controlado y eficiente de los recursos. La versi\'on de YARN utilizada en este proyecto es la 2.5.0, pero no de la distribuci\'on oficial, si no de la distribuci\'on que hace la empresa Cloudera, de la cual pasamos a hablar a continuaci\'on.

\textbf{Cloudera} es una empresa estadounidense que proporciona soporte para diferentes productos entre los que se encuentra su propia distribuci\'on de Hadoop, la cual incluye otras herramientas y servicios relacionados. Su producto ha sido utilizado en este proyecto y podemos dividirlo claramente en dos partes. Por un lado tenemos Cloudera Manager, encargado de distribuir el software a lo largo del cluster, y adem\'as monitorear y configurar los servicios desplegados. Por otro lado, tenemos la distribuci\'on de Hadoop de Cloudera que es la que contiene todos los ficheros necesarios para la ejecuci\'on de los servicios. Tanto la versi\'on de Cloudera Manager utilizada, como la de la distribuci\'on de Hadoop de Cloudera han sido la misma, 5.3.2, esta versi\'on de la distribuci\'on contiene la versi\'on 2.5.0 de Hadoop.

Cloudera, y por consiguiente Hadoop, ha sido distribuido a lo largo de \textbf{6 m\'aquinas} conectadas por un switch que operaba a una velocidad de 100 Mbits/s. Todas las m\'aquinas estaban compuestas por 16 GB de memoria RAM, 80 GB de disco duro y tenían instalado el sistema operativo CentOS en su versi\'on 6.6. Respecto a los procesadores, 4 de las m\'aquinas poseían 2 procesadores con 4 n\'ucleos de procesamiento cada uno y las otras dos m\'aquinas tenían 2 procesadores con 2 n\'ucleos de procesamiento cada uno.

Para acelerar el procesamiento de imágenes en el problema de reconocimiento facial se ha hecho uso de la librer\'ia \textbf{OpenCV} en su versi\'on 2.4.10. Este software fue instalado en todas y cada una de las m\'aquinas del cluster, esto fue necesario ya que las tareas de Hadoop que se ejecutan de forma distribuida para el problema de reconocimiento facial hacen uso de esta librer\'ia.

Con respecto al entorno de desarrollo utilizado, el elegido ha sido \textbf{Eclipse} en su versi\'on 4.4.1 (Luna). Este ha sido utilizado para desarrollar la implementaci\'on en Java de las diferentes partes del proyecto. El sistema operativo donde estaba instalado es Mac OSX Yosemite.









