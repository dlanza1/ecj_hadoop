Antes de llegar a la implementaci\'on descrita, se realiz\'o una implementación menos perfeccionada. \'Esta fue testada y se obtuvieron los tiempos que se pueden observar en la primera parte de la sección de resultados \verapartado{resultados-sin-mejoras}. Tras estas pruebas se refin\'o la implementación introduciendo algunas mejoras y se realizaron configuraciones que consiguieron que la fase de evaluación se ejecutara en menos tiempo \verapartado{resultados-mejoras}. Estas modificaciones a la primera implementación se listan a continuación:
\label{mejoras}

\begin{itemize}
	\item \textbf{Uso de la cache distribuida.} En principio el checkpoint se almacenaba en el sistema de ficheros (HDFS) desde donde se leía por todos los nodos, pero de esta manera el fichero estaba solo almacenado en algunos de los nodos del cluster (en tantos nodos como replicas de los bloques, por defecto 3). Los nodos que no contenían el fichero necesitaban mas tiempo para leerlo, ya que conllevaba transferirlo en primer lugar a través de la red. Gracias a almacenar el checkpoint en la cache distribuida, el fichero se distribuye a lo largo de todos los nodos del cluster y por consiguiente la lectura es mucho mas rápida.
	\item \textbf{Checkpoint sin la población.} La implementación realizada establece dos entradas para el trabajo de Hadoop, una es la población almacenada en HDFS y otra es el fichero de checkpoint el cual contiene el estado de la evolución (incluida la población). Siendo así, se ha eliminado la población del checkpoint ya que se lee desde el sistema de ficheros y de esta manera se disminuye considerablemente el tamaño del fichero, acelerando as\'i su escritura y posterior lectura.
	\item \textbf{Leer checkpoint solo una vez.} El checkpoint debe ser leído por cada tarea que va a evaluar a los individuos, es por esto que se implement\'o su lectura en un método llamado setup() que se ejecuta una sola vez al principio de la tarea. Esto conlleva la lectura por cada tarea lanzada, si en vez de en el método setup(), implementamos la lectura en la inicializaci\'on del lector de la entrada del trabajo de Hadoop (InputReader), conseguiremos que solo sea leído una vez por cada una de las m\'aquinas en cada trabajo.
	\item \textbf{Evaluar los individuos necesarios.} Debido a distintos fenómenos como el del elitismo, se puede dar el caso de que algunos de los individuos de la población ya est\'en evaluados (en caso del elitismo porque son individuos que provienen directamente de la generaci\'on anterior), esto hace que el fitness ya haya sido calculado y que no sea necesario volverlos a evaluar. Los individuos que se encuentren en esta circunstancias no se incluirán en el fichero de entrada del trabajo de Hadoop.		
	\item \textbf{Compresi\'on de ficheros.} En el trabajo que se lanza en Hadoop, hay ficheros tanto de entrada (la población) como de salida (resultados de la evaluación) y ambos pueden tener un tamaño considerable si contemplamos poblaciones de millones de individuos. Estos ficheros pueden ser comprimidos con el objetivo de ser transferidos mas rápidamente a trav\'es de la red. Los ficheros de entrada deben ser transferidos desde el cliente (en este caso ECJ) hasta el sistema de ficheros, HDFS, y los ficheros de salida desde HDFS hasta el cliente para asignar el resultado, esto hace que el uso de la compresión acelere los tiempos de transferencia y por consiguiente mejore el tiempo de evaluación.
	\item \textbf{Buffers aumentados.} Como se mencionaba en el punto anterior, los ficheros pueden llegar a ser de tamaños considerables por lo que es conveniente que los buffers encargados de las transferencias a través de la red tengan tamaños grandes, acordes al tamaño del fichero a transferir. Es por esto que el buffer para crear la entrada del trabajo como el encargado de recibir los resultados han sido aumentados.
	\item \textbf{Reuso de las m\'aquinas virtuales de Java.} Hadoop est\'a implementado en Java y por consiguiente, hace uso de maquinas virtuales de Java (JVM por su siglas en ingl\'es) para su ejecuci\'on. Cada una de las tareas que se lanzan en los nodos que componen el cluster conlleva la creaci\'on y destrucii\'on de la JVM. Para tareas donde la ejecuci\'on conlleva varios minutos, el tiempo necesario para crear y destruir la JVM puede ser despreciable, pero si las tareas toman pocos segundos puede tener importancia. Hadoop puede ser configurado para que no se cree una JVM por cada tarea, de manera que son reutilizadas para otras tareas tantas veces como se configure.
	\item \textbf{Serializaci\'on de los ficheros de entrada y salida.} En la primera implementación realizada, los ficheros tanto de la población (la entrada) como los que contienen los resultados de fitness (salida), eran escritos en formato texto. Los ficheros en formato texto requieren para su lectura y escritura que la información sea parseada a sus correspondientes tipos y adem\'as suelen ocupar mas que los ficheros binarios. Es por esto que se decidió realizar la implementación para que ambos ficheros sean binarios, facilitando así la escritura y lectura de los datos y adem\'as consiguiendo que los mismos reduzcan su tamaño.
\end{itemize}













